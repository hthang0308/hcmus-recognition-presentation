@misc{ravanelli2019speaker,
      title={Speaker Recognition from Raw Waveform with SincNet}, 
      author={Mirco Ravanelli and Yoshua Bengio},
      year={2019},
      eprint={1808.00158},
      archivePrefix={arXiv},
      primaryClass={eess.AS}
}

@INPROCEEDINGS{15_0185,
  author={Nanxin Chen, Yanmin Qian, Kai Yu},
  booktitle={INTERSPEECH 2015 16th Annual Conference of the International Speech Communication Association}, 
  title={Multi-Task Learning for Text-Dependent Speaker Verification}, 
  year={2015},
  volume={},
  number={},
  pages={185-189},
}

@INPROCEEDINGS{6854363,
  author={Variani, Ehsan and Lei, Xin and McDermott, Erik and Moreno, Ignacio Lopez and Gonzalez-Dominguez, Javier},
  booktitle={2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Deep neural networks for small footprint text-dependent speaker verification}, 
  year={2014},
  volume={},
  number={},
  pages={4052-4056},
  doi={10.1109/ICASSP.2014.6854363}}

@INPROCEEDINGS{8461375,
  author={Snyder, David and Garcia-Romero, Daniel and Sell, Gregory and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={X-Vectors: Robust DNN Embeddings for Speaker Recognition}, 
  year={2018},
  volume={},
  number={},
  pages={5329-5333},
  doi={10.1109/ICASSP.2018.8461375}}
  
@inproceedings{10.1145/3287921.3287954,
author = {Nguyen, Son T. and Lai, Viet D. and Dam-Ba, Quyen and Nguyen-Xuan, Anh and Pham, Cuong},
title = {Vietnamese Speaker Authentication Using Deep Models},
year = {2018},
isbn = {9781450365390},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3287921.3287954},
doi = {10.1145/3287921.3287954},
abstract = {Speaker Authentication is the identification of a user from voice biometrics and has a wide range of applications such as banking security, human computer interaction and ambient authentication. In this work, we investigate the effectiveness of acoustic features such as Mel-frequency cepstral coefficients (MFCC), Gammatone frequency cepstral coefficients (GFCC), and Linear Predictive Codes (LPC) extracted from audio streams for constructing feature spectral images. In addition, we propose to use the deep Residual Network models for user verification from feature spectrum images. We evaluate our proposed method under two settings over the dataset collected from 20 Vietnamese speakers. The results, with the Equal Error rate of around 4%, have demonstrated that the feasibility of Vietnamese speaker authentication by using deep Residual Network models trained with GFCC spectral feature images.},
booktitle = {Proceedings of the Ninth International Symposium on Information and Communication Technology},
pages = {177–184},
numpages = {8},
keywords = {Speaker Authentication, Biometrics, Gaussian mixture model, Residual Networks},
location = {Danang City, Viet Nam},
series = {SoICT 2018}
}

@article{Liu_2020,
   title={Mockingjay: Unsupervised Speech Representation Learning with Deep Bidirectional Transformer Encoders},
   ISBN={9781509066315},
   url={http://dx.doi.org/10.1109/ICASSP40776.2020.9054458},
   DOI={10.1109/icassp40776.2020.9054458},
   journal={ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
   publisher={IEEE},
   author={Liu, Andy T. and Yang, Shu-wen and Chi, Po-Han and Hsu, Po-chun and Lee, Hung-yi},
   year={2020},
   month={May}
}

@misc{jung2020improved,
      title={Improved RawNet with Feature Map Scaling for Text-independent Speaker Verification using Raw Waveforms}, 
      author={Jee-weon Jung and Seung-bin Kim and Hye-jin Shim and Ju-ho Kim and Ha-Jin Yu},
      year={2020},
      eprint={2004.00526},
      archivePrefix={arXiv},
      primaryClass={eess.AS}
}

@misc{pascual2019learning,
      title={Learning Problem-agnostic Speech Representations from Multiple Self-supervised Tasks}, 
      author={Santiago Pascual and Mirco Ravanelli and Joan Serrà and Antonio Bonafonte and Yoshua Bengio},
      year={2019},
      eprint={1904.03416},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{originalsourcecode,
title={Github Repository: SincNet original code written in PyTorch by the autor},
author={Mirco Ravanelli and Yoshua Bengio},
year={2019},
url={https://github.com/mravanelli/SincNet}
}

@misc{kerassourcecode,
title={Github Repository: Keras (tensorflow) implementation of SincNet (Mirco Ravanelli, Yoshua Bengio},
author={Francesco Grauso, Evans Kiplagat},
year={2018},
url={https://github.com/grausof/keras-sincnet}
}

@misc{coria2020comparison,
      title={A Comparison of Metric Learning Loss Functions for End-To-End Speaker Verification}, 
      author={Juan M. Coria and Hervé Bredin and Sahar Ghannay and Sophie Rosset},
      year={2020},
      eprint={2003.14021},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{companionrepository,
title={Github Repository: Companion repository for the paper "A Comparison of Metric Learning Loss Functions for End-to-End Speaker Verification" published at SLSP 2020},
author={Juan M. Coria and Hervé Bredin and Sahar Ghannay and Sophie Rosset},
year={2020},
url={https://github.com/juanmc2005/SpeakerEmbeddingLossComparison}
}

@misc{wavencoder,
title={Github Repository: WavEncoder - a Python library for encoding raw audio with PyTorch backend.},
url={https://github.com/shangeth/wavencoder}
}

@misc{schneider2019wav2vec,
      title={wav2vec: Unsupervised Pre-training for Speech Recognition}, 
      author={Steffen Schneider and Alexei Baevski and Ronan Collobert and Michael Auli},
      year={2019},
      eprint={1904.05862},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{schneider2019wav2vec2,
title={Wav2vec 2.0: Learning the structure of speech from raw audio},
url={https://ai.facebook.com/blog/wav2vec-20-learning-the-structure-of-speech-from-raw-audio/}
}

@ARTICLE{7847321,
  author={Ghahabi, Omid and Hernando, Javier},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
  title={Deep Learning Backend for Single and Multisession i-Vector Speaker Recognition}, 
  year={2017},
  volume={25},
  number={4},
  pages={807-817},
  doi={10.1109/TASLP.2017.2661705}}
  
 @book{10.5555/1952072,
author = {Jain, Anil K. and Flynn, Patrick and Ross, Arun A.},
title = {Handbook of Biometrics},
year = {2010},
isbn = {1441943757},
publisher = {Springer Publishing Company, Incorporated},
edition = {1st},
abstract = {Biometrics is a rapidly evolving field with applications ranging from accessing ones computer to gaining entry into a country. The deployment of large-scale biometric systems in both commercial and government applications has increased public awareness of this technology. Recent years have seen significant growth in biometric research resulting in the development of innovative sensors, new algorithms, enhanced test methodologies and novel applications. This book addresses this void by inviting some of the prominent researchers in Biometrics to contribute chapters describing the fundamentals as well as the latest innovations in their respective areas of expertise.}
}

@misc{tang2016multitask,
      title={Multi-task Recurrent Model for Speech and Speaker Recognition}, 
      author={Zhiyuan Tang and Lantian Li and Dong Wang},
      year={2016},
      eprint={1603.09643},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@INPROCEEDINGS{1467314,
  author={Chopra, S. and Hadsell, R. and LeCun, Y.},
  booktitle={2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)}, 
  title={Learning a similarity metric discriminatively, with application to face verification}, 
  year={2005},
  volume={1},
  number={},
  pages={539-546 vol. 1},
  doi={10.1109/CVPR.2005.202}}
  
@misc{IAFPA19_xvectors_Kelly_et_al_presentation.,
      title={From i-vectors to x-vectors – a generational change in speaker recognition illustrated on the NFI-FRIDA database}, 
      journal={The International Association for Forensic Phonetics and Acoustics (IAFPA), Istanbul},
      author={Finnian Kelly (1), Anil Alexander (1), Oscar Forth (1), and David van der Vloed (2)},
      school={(1): Oxford Wave Research Ltd., Oxford, United Kingdom ;(2): Speech and Audio Research, Netherlands Forensic Institute, The Hague, Netherlands}
      year={2019}
}
